{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Лабараторная 5\n",
    "## Выбор признаков"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "166f04791121115d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Был выбран датасет твитов с времени пандемии Covid19\n",
    "Признаки:\n",
    "- UserName\n",
    "- ScreenName\n",
    "- Location\n",
    "- TweetAt\n",
    "- OriginalTweet\n",
    "- Sentiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a3f997e9f7354e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Были выбраны классификаторы:\n",
    "- LogisticRegression\n",
    "- RandomForestClassifier\n",
    "- SVC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1204d6116d709f24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, SelectFromModel, SequentialFeatureSelector, VarianceThreshold\n",
    "\n",
    "from filter_method import manual_chi2\n",
    "from wrapper_method import manual_rfe\n",
    "from build_data import get_processed_data\n",
    "from inner_method import rf_embedded_selection\n",
    "from dimenshion_reduce import apply_pca, apply_tsne\n",
    "from lib_realizations import filter_lib, inner_lib, wrapper_lib\n",
    "from plot_graps import plot_data_with_class, plot_data_with_cluster"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f75cef7e215c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка и предобработка данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8574af027fcbbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d23bc671b028f5f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Предобработка данных, 5 классов в данном датасете, векторизация текста через TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67c514b058f4c58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    custom_mapping = {'Neutral': 0, 'Positive': 1, 'Negative': 2,\n",
    "                      'Extremely Positive': 3, 'Extremely Negative': 4}\n",
    "    df['Sentiment'] = df['Sentiment'].map(custom_mapping)\n",
    "\n",
    "    y = df['Sentiment']\n",
    "    \n",
    "    X_text = df['OriginalTweet']\n",
    "    X_location = df['Location'].fillna('Unknown')\n",
    "    X_date = pd.to_datetime(df['TweetAt'], errors='coerce', dayfirst=True)\n",
    "\n",
    "    df['DayOfWeek'] = X_date.dt.dayofweek\n",
    "    df['IsWeekend'] = (X_date.dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_text_vectorized = vectorizer.fit_transform(X_text).toarray()\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_location_encoded = encoder.fit_transform(X_location.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "    X_time = df[['DayOfWeek', 'IsWeekend']].values\n",
    "\n",
    "    X = np.hstack((X_text_vectorized, X_location_encoded, X_time))\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "\n",
    "    text_features = vectorizer.get_feature_names_out()\n",
    "    location_features = encoder.get_feature_names_out(['Location'])\n",
    "    time_features = ['DayOfWeek', 'IsWeekend']\n",
    "\n",
    "    all_feature_names = np.array(list(text_features) + list(location_features) + time_features, dtype=object)\n",
    "\n",
    "    return X, y, all_feature_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37efe85663320a92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделение данных на тренировочную и валидационную выборку"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c941efcfd4e9b2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f72c5709a13262"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_processed_data(file_path='Corona_NLP_test.csv'):\n",
    "    df = load_data(file_path)\n",
    "    X, y, all_feature_names = preprocess_data(df)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = split_data(X, y)\n",
    "\n",
    "    return X_train, y_train.values, X_val, y_val.values, all_feature_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fd35200b82bdb67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Загрузка данных, создание классификаторов, расчет качества без FS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dfd897d9efe4e13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_classifiers(classifiers, X_train, y_train, X_val, y_val):\n",
    "    accuracies = []\n",
    "    for name, clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"{name}: {acc:.4f}\")\n",
    "    return accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4c4634c0a39f727"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"1. Load data...\")\n",
    "X_train, y_train, X_val, y_val, all_feature_names = get_processed_data(\"Corona_NLP_test.csv\")\n",
    "\n",
    "classifiers = [\n",
    "        (\"LogisticRegression\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        (\"RandomForest\", RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)),\n",
    "        (\"SVC\", SVC(random_state=42))\n",
    "    ]\n",
    "\n",
    "print(\"\\n=== Accuracy without FS ===\")\n",
    "accuracies_before_fs = evaluate_classifiers(classifiers, X_train, y_train, X_val, y_val)\n",
    "\n",
    "fs_accuracies = {\"No_FS\": accuracies_before_fs}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5f34255a7a61243"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter method (Custom)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef4983516656145d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def manual_chi2(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    classes = np.unique(y)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    class_counts = np.array([(y == c).sum() for c in classes])\n",
    "    counts = np.zeros((n_classes, n_features), dtype=int)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        row_features = np.where(X[i] != 0)[0]\n",
    "        class_idx = np.searchsorted(classes, y[i])\n",
    "        for f in row_features:\n",
    "            counts[class_idx, f] += 1\n",
    "\n",
    "    total_presence = counts.sum(axis=0)\n",
    "    total_absence = n_samples - total_presence\n",
    "    chi2_scores = np.zeros(n_features, dtype=float)\n",
    "\n",
    "    for f in range(n_features):\n",
    "        observed_presence = counts[:, f]\n",
    "        observed_absence = class_counts - observed_presence\n",
    "        if total_presence[f] == 0 or total_presence[f] == n_samples:\n",
    "            chi2_scores[f] = 0\n",
    "            continue\n",
    "\n",
    "        expected_presence = class_counts * (total_presence[f] / n_samples)\n",
    "        expected_absence = class_counts * (total_absence[f] / n_samples)\n",
    "        chi2_val = 0.0\n",
    "\n",
    "        for c_idx in range(n_classes):\n",
    "            if expected_presence[c_idx] > 0:\n",
    "                chi2_val += ((observed_presence[c_idx] - expected_presence[c_idx]) ** 2) / expected_presence[c_idx]\n",
    "            if expected_absence[c_idx] > 0:\n",
    "                chi2_val += ((observed_absence[c_idx] - expected_absence[c_idx]) ** 2) / expected_absence[c_idx]\n",
    "\n",
    "        chi2_scores[f] = chi2_val\n",
    "\n",
    "    return chi2_scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48925b44ca1c80d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Работа с фильтрующим методом"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fc6918a63f22cc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n2. Filter method (chi^2)...\")\n",
    "chi2_scores = manual_chi2(X_train, y_train)\n",
    "chi2_sorted_indices = np.argsort(chi2_scores)[::-1]\n",
    "\n",
    "top_k_chi2 = 30\n",
    "selected_indices_chi2 = chi2_sorted_indices[:top_k_chi2]\n",
    "\n",
    "X_train_chi2 = X_train[:, selected_indices_chi2]\n",
    "X_val_chi2 = X_val[:, selected_indices_chi2]\n",
    "\n",
    "top_30_chi2_features = all_feature_names[selected_indices_chi2]\n",
    "\n",
    "print(\"\\nTop 30 wia chi^2:\")\n",
    "for f in top_30_chi2_features:\n",
    "    print(f)\n",
    "\n",
    "print(\"\\n=== Accuracy after chi^2 FS ===\")\n",
    "accuracies_chi2 = evaluate_classifiers(classifiers, X_train_chi2, y_train, X_val_chi2, y_val)\n",
    "fs_accuracies[\"Chi2\"] = accuracies_chi2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f30932ef088e86bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedded method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffd590b1f9877f14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rf_embedded_selection(X, y, num_features=30, n_estimators=100, random_state=42, max_depth=None):\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, max_depth=max_depth)\n",
    "    rf.fit(X, y)\n",
    "    importances = rf.feature_importances_\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    selected_indices = sorted_indices[:num_features]\n",
    "    mask = np.zeros(X.shape[1], dtype=bool)\n",
    "    mask[selected_indices] = True\n",
    "    return mask, selected_indices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc90b662d5569c13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Работа с встроенным методом"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47523b52b55540d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n3. Embedded method (Random Forest FS)...\")\n",
    "mask_embedded, ranking_embedded = rf_embedded_selection(\n",
    "    X_train, y_train, num_features=30, n_estimators=100, random_state=42\n",
    ")\n",
    "\n",
    "X_train_embedded = X_train[:, mask_embedded]\n",
    "X_val_embedded = X_val[:, mask_embedded]\n",
    "\n",
    "top_30_embedded_indices = ranking_embedded[:30]\n",
    "top_30_embedded_features = all_feature_names[top_30_embedded_indices]\n",
    "print(\"\\nTop 30 wia embedded method (RF):\")\n",
    "for f in top_30_embedded_features:\n",
    "    print(f)\n",
    "    \n",
    "print(\"\\n=== Accuracy afrer embedded method (RF) ===\")\n",
    "accuracies_embedded = evaluate_classifiers(classifiers, X_train_embedded, y_train, X_val_embedded, y_val)\n",
    "fs_accuracies[\"Embedded_RF\"] = accuracies_embedded"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "443acf0b6a63f9b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapper method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d559ad8b15624f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def manual_rfe(X, y, base_estimator, n_features_to_select=30):\n",
    "    selected_features = list(range(X.shape[1]))\n",
    "    ranking = []\n",
    "\n",
    "    while len(selected_features) > n_features_to_select:\n",
    "        clf = clone(base_estimator)\n",
    "        clf.fit(X[:, selected_features], y)\n",
    "\n",
    "        if hasattr(clf, 'feature_importances_'):\n",
    "            importances = clf.feature_importances_\n",
    "        elif hasattr(clf, 'coef_'):\n",
    "            importances = np.abs(clf.coef_).flatten()\n",
    "        else:\n",
    "            raise ValueError(\"Base classifier did not support feature_importances_ or coef_.\")\n",
    "\n",
    "        least_important_index = np.argmin(importances)\n",
    "        least_important_feature = selected_features[least_important_index]\n",
    "\n",
    "        ranking.append(least_important_feature)\n",
    "\n",
    "        selected_features.pop(least_important_index)\n",
    "\n",
    "    mask = np.zeros(X.shape[1], dtype=bool)\n",
    "    mask[selected_features] = True\n",
    "\n",
    "    clf_final = clone(base_estimator)\n",
    "    clf_final.fit(X[:, selected_features], y)\n",
    "\n",
    "    if hasattr(clf_final, 'feature_importances_'):\n",
    "        final_importances = clf_final.feature_importances_\n",
    "    elif hasattr(clf_final, 'coef_'):\n",
    "        final_importances = np.abs(clf_final.coef_).flatten()\n",
    "    else:\n",
    "        raise ValueError(\"Base classifier did not support feature_importances_ or coef_.\")\n",
    "\n",
    "    sorted_indices = np.argsort(final_importances)[::-1]\n",
    "    sorted_features = [selected_features[i] for i in sorted_indices]\n",
    "    ranking = sorted_features + ranking\n",
    "\n",
    "    ranking = np.array(ranking)\n",
    "\n",
    "    return mask, ranking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb361d19642bcc5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Работа с методом оберткой"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a944a3796f0b3a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n4. Wrapper method (Custom RFE)...\")\n",
    "base_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "n_features_to_select = 30\n",
    "\n",
    "mask_wr, ranking_wr = manual_rfe(\n",
    "    X_train, y_train,\n",
    "    base_estimator=base_clf,\n",
    "    n_features_to_select=n_features_to_select\n",
    ")\n",
    "\n",
    "X_train_wr = X_train[:, mask_wr]\n",
    "X_val_wr = X_val[:, mask_wr]\n",
    "\n",
    "top_30_wr_features = all_feature_names[ranking_wr[:30]]\n",
    "print(\"\\nTop 30 wia wrapper method (RFE):\")\n",
    "for f in top_30_wr_features:\n",
    "    print(f)\n",
    "    \n",
    "print(\"\\n=== Accuracy after custom_RFE ===\")\n",
    "accuracies_wr = evaluate_classifiers(classifiers, X_train_wr, y_train, X_val_wr, y_val)\n",
    "fs_accuracies[\"Wrapper_RFE\"] = accuracies_wr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8b26aeb063c85a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Библиотечные методы"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a136e39d8f83101"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Убираем констаные признаки"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23621517de048fdf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_constant_features(X, feature_names=None, selector=None):\n",
    "    if selector is None:\n",
    "        selector = VarianceThreshold(threshold=0)\n",
    "        X_new = selector.fit_transform(X)\n",
    "        if feature_names is not None:\n",
    "            support_mask = selector.get_support()\n",
    "            updated_feature_names = feature_names[support_mask]\n",
    "            return X_new, updated_feature_names, selector\n",
    "        else:\n",
    "            return X_new, None, selector\n",
    "    else:\n",
    "        X_new = selector.transform(X)\n",
    "        return X_new, feature_names, selector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717b342fd38e6855"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Filter Lib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8631fe206212c4a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_lib(X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, k=30):\n",
    "    X_train, all_feature_names, vt_selector = remove_constant_features(X_train, all_feature_names)\n",
    "    X_val, _, _ = remove_constant_features(X_val, all_feature_names, vt_selector)\n",
    "\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_new = selector.fit_transform(X_train, y_train)\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    top_features = all_feature_names[selected_indices]\n",
    "\n",
    "    print(\"\\nTop 30 features wia filter method (f_classif):\")\n",
    "    for feature in top_features[:30]:\n",
    "        print(feature)\n",
    "\n",
    "    X_val_new = X_val[:, selected_indices]\n",
    "\n",
    "    accuracies_after_filter = evaluate_classifiers(classifiers, X_train_new, y_train, X_val_new, y_val)\n",
    "    return accuracies_after_filter, selected_indices, top_features, X_train_new, X_val_new"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27d8fd6ce67dffb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Embedded lib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78b81aafb527322d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inner_lib(X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, threshold='mean'):\n",
    "    X_train, all_feature_names, vt_selector = remove_constant_features(X_train, all_feature_names)\n",
    "    X_val, _, _ = remove_constant_features(X_val, all_feature_names, vt_selector)\n",
    "\n",
    "    lsvc = LinearSVC(C=0.5, penalty=\"l1\", random_state=42, max_iter=1000)\n",
    "    model = SelectFromModel(lsvc, threshold=threshold)\n",
    "    X_train_new = model.fit_transform(X_train, y_train)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    top_features = all_feature_names[selected_indices]\n",
    "\n",
    "    print(\"\\nTop 30 features wia embedded method (LinearSVC + L1):\")\n",
    "    for f in top_features[:30]:\n",
    "        print(f)\n",
    "\n",
    "    X_val_new = X_val[:, selected_indices]\n",
    "    accuracies_after_inner = evaluate_classifiers(classifiers, X_train_new, y_train, X_val_new, y_val)\n",
    "    return accuracies_after_inner, selected_indices, top_features, X_train_new, X_val_new"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0832970b72b657d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Wrapper lib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d575fe05cbc0f418"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def wrapper_lib(X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, n_features=30):\n",
    "\n",
    "    X_train, all_feature_names, vt_selector = remove_constant_features(X_train, all_feature_names)\n",
    "    X_val, _, _ = remove_constant_features(X_val, all_feature_names, vt_selector)\n",
    "    \n",
    "    base_estimator = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    sfs = SequentialFeatureSelector(base_estimator, n_features_to_select=n_features, direction='forward', n_jobs=-1)\n",
    "    X_train_new = sfs.fit_transform(X_train, y_train)\n",
    "    selected_indices = sfs.get_support(indices=True)\n",
    "    top_features = all_feature_names[selected_indices]\n",
    "\n",
    "    print(\"\\nTop 30 features wia wrapper method (SFS):\")\n",
    "    for f in top_features[:30]:\n",
    "        print(f)\n",
    "\n",
    "    X_val_new = X_val[:, selected_indices]\n",
    "    accuracies_after_wrapper = evaluate_classifiers(classifiers, X_train_new, y_train, X_val_new, y_val)\n",
    "    return accuracies_after_wrapper, selected_indices, top_features, X_train_new, X_val_new"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4106df8c4174438"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация использования библиотечных методов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c41f1a444fcbbc9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n=== Lib FS methods ===\")\n",
    "\n",
    "\n",
    "accuracies_filter, filter_indices, filter_features, X_train_filter, X_val_filter = filter_lib(\n",
    "    X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, k=30\n",
    ")\n",
    "fs_accuracies[\"Filter_f_classif_lib\"] = accuracies_filter\n",
    "\n",
    "\n",
    "accuracies_inner, inner_indices, inner_features, X_train_inner, X_val_inner = inner_lib(\n",
    "    X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, threshold='mean'\n",
    ")\n",
    "fs_accuracies[\"Inner_L1SVC_lib\"] = accuracies_inner\n",
    "\n",
    "\n",
    "accuracies_wrapper, wrapper_indices, wrapper_features, X_train_wrapper, X_val_wrapper = wrapper_lib(\n",
    "    X_train, y_train, X_val, y_val, all_feature_names, classifiers, evaluate_classifiers, n_features=30\n",
    ")\n",
    "fs_accuracies[\"Wrapper_SFS_lib\"] = accuracies_wrapper"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44112e3d689c3e12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Реализация выбора лучшего FS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23d43c9c9fa78a96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nChoose best FS method...\")\n",
    "average_accuracies = {method: np.mean(acc) for method, acc in fs_accuracies.items()}\n",
    "for method, avg_acc in average_accuracies.items():\n",
    "    print(f\"{method}: average accuracy = {avg_acc:.4f}\")\n",
    "best_fs_method = max(average_accuracies, key=average_accuracies.get)\n",
    "print(f\"\\nBest FS method: {best_fs_method} with accuracy {average_accuracies[best_fs_method]:.4f}\")\n",
    "\n",
    "if best_fs_method == \"No_FS\":\n",
    "    X_train_best_fs = X_train\n",
    "elif best_fs_method == \"Chi2_manual\":\n",
    "    X_train_best_fs = X_train_chi2\n",
    "elif best_fs_method == \"Embedded_RF_manual\":\n",
    "    X_train_best_fs = X_train_embedded\n",
    "elif best_fs_method == \"Wrapper_RFE_manual\":\n",
    "    X_train_best_fs = X_train_wr\n",
    "elif best_fs_method == \"Filter_f_classif_lib\":\n",
    "    X_train_best_fs = X_train_filter\n",
    "elif best_fs_method == \"Inner_L1SVC_lib\":\n",
    "    X_train_best_fs = X_train_inner\n",
    "elif best_fs_method == \"Wrapper_SFS_lib\":\n",
    "    X_train_best_fs = X_train_wrapper\n",
    "else:\n",
    "    raise ValueError(\"Unexpecded FS method\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "193f60a001280db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Кластеризация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f4369f6aeab0143"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nClusterization...\")\n",
    "kmeans_before = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans_before.fit(X_train)\n",
    "labels_before = kmeans_before.labels_\n",
    "\n",
    "kmeans_after = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans_after.fit(X_train_best_fs)\n",
    "labels_after = kmeans_after.labels_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a5c5dad0b2c2cbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оценка качества кластеризации"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f61e292cff3d570"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ari_before = adjusted_rand_score(y_train, labels_before)\n",
    "sil_before = silhouette_score(X_train, labels_before)\n",
    "ari_after = adjusted_rand_score(y_train, labels_after)\n",
    "sil_after = silhouette_score(X_train_best_fs, labels_after)\n",
    "\n",
    "print(\"\\nClusterization quality:\")\n",
    "print(f\"Before FS: ARI={ari_before:.4f}, Silhouette={sil_before:.4f}\")\n",
    "print(f\"After FS ({best_fs_method}): ARI={ari_after:.4f}, Silhouette={sil_after:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fbbfef75cddad9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Уменьшение размерности \n",
    "- PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d90c8b3d4a36ddcd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_pca(X, n_components=2, random_state=42):\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beeceed66af9f6d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- TSNE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb0c2178942bcbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_tsne(X, n_components=2, random_state=42, perplexity=30):\n",
    "    tsne = TSNE(n_components=n_components, random_state=random_state, perplexity=perplexity, init='pca')\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    return X_tsne"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91d3caba705f696a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Применение уменьшения размерности на данных, визуализация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43e09e13281dd9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_pca = apply_pca(X_train)\n",
    "X_train_best_fs_pca = apply_pca(X_train_best_fs)\n",
    "\n",
    "plot_data_with_class(X_train_pca, y_train, title=f\"Original classes (PCA, BEFORE FS)\")\n",
    "plot_data_with_class(X_train_best_fs_pca, y_train, title=f\"Original classes (PCA, AFTER FS: {best_fs_method})\")\n",
    "\n",
    "plot_data_with_cluster(X_train_pca, labels_before, title=\"Clusters (PCA, BEFORE FS)\")\n",
    "plot_data_with_cluster(X_train_best_fs_pca, labels_after, title=f\"Clusters (PCA, AFTER FS: {best_fs_method})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "836d3b37e1f622d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_tsne = apply_tsne(X_train)\n",
    "X_train_best_fs_tsne = apply_tsne(X_train_best_fs)\n",
    "\n",
    "plot_data_with_class(X_train_tsne, y_train, title=\"Original classes (t-SNE, BEFORE FS)\")\n",
    "plot_data_with_class(X_train_best_fs_tsne, y_train, title=f\"Original classes (t-SNE, AFTER FS: {best_fs_method})\")\n",
    "\n",
    "plot_data_with_cluster(X_train_tsne, labels_before, title=\"Clusters (t-SNE, BEFORE FS)\")\n",
    "plot_data_with_cluster(X_train_best_fs_tsne, labels_after, title=f\"Clusters (t-SNE, AFTER FS: {best_fs_method})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e629d0b3449f185"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализация:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e216703f5dca8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_data_with_class(X_2d, y, title=\"Original classes\", xlabel=\"Dim 1\", ylabel=\"Dim 2\"):\n",
    "    unique_classes = np.unique(y)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for cls in unique_classes:\n",
    "        mask = (y == cls)\n",
    "        cluster_size = np.sum(mask)\n",
    "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1], label=f\"Class {cls} (N={cluster_size})\", s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "776366a39c97cf8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_data_with_cluster(X_2d, labels, title=\"Clusters\", xlabel=\"Dim 1\", ylabel=\"Dim 2\"):\n",
    "    unique_clusters = np.unique(labels)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        mask = (labels == cluster)\n",
    "        cluster_size = np.sum(mask)\n",
    "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1], s=10, label=f\"Cluster {cluster} (N={cluster_size})\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90af66d1b48e028e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
